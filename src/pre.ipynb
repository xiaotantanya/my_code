{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.nn.modules.module.Module'>\n"
     ]
    }
   ],
   "source": [
    "module = importlib.import_module(\"torch.nn\")\n",
    "print(getattr(module,\"Module\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<argparse._ArgumentGroup object at 0x7effc86225b0>\n",
      "<argparse._ArgumentGroup object at 0x7effc8622a30>\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\"--f\",help=\"tre\")\n",
    "print(parser._action_groups[0])\n",
    "print(parser._action_groups[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dadd3a1d447c4bd2aa0f58dd866a4305",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64b8411f91b34312a5c262b60a95c6b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)okenizer_config.json:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f0bde28705545728f70ee9f2702b973",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "298df038f8e8441a9493276ede2b17ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/440M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'am', '[MASK]', 'student']\n",
      "MaskedLMOutput(loss=None, logits=tensor([[[-7.0836, -7.1535, -7.0896,  ..., -6.3079, -6.1164, -3.7147],\n",
      "         [-7.9648, -8.0580, -8.0186,  ..., -6.8658, -6.6078, -4.2644],\n",
      "         [-7.0189, -7.0385, -7.1028,  ..., -6.4154, -5.8327, -3.5333],\n",
      "         [-8.5992, -8.7210, -8.6977,  ..., -7.4474, -7.0835, -4.4442]]],\n",
      "       grad_fn=<AddBackward0>), hidden_states=None, attentions=None)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer,AutoModelForMaskedLM,BertTokenizer,BertModel,BertForMaskedLM\n",
    "import torch\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "model = BertForMaskedLM.from_pretrained(\"bert-base-uncased\")\n",
    "text = \"I am a student\"\n",
    "tokenized_text = tokenizer.tokenize(text)\n",
    "masked_index = 2\n",
    "tokenized_text[masked_index] = \"[MASK]\"\n",
    "print(tokenized_text)\n",
    "indexed_tokens = tokenizer.convert_tokens_to_ids(tokenized_text)\n",
    "tokens_tensor = torch.tensor([indexed_tokens])\n",
    "output = model(tokens_tensor)\n",
    "print(output)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Parameter containing:\n",
      "tensor([[-0.0047, -0.0510, -0.0929,  ..., -0.0600, -0.0602,  0.0653],\n",
      "        [-0.0147,  0.0543,  0.0725,  ..., -0.0117, -0.0229,  0.0279],\n",
      "        [ 0.0608,  0.0683, -0.0976,  ..., -0.0792,  0.0810,  0.0440],\n",
      "        ...,\n",
      "        [-0.0344,  0.0899, -0.0403,  ...,  0.0380, -0.0524, -0.0115],\n",
      "        [ 0.0288,  0.0027, -0.0553,  ..., -0.0563, -0.0044, -0.0741],\n",
      "        [ 0.0607, -0.0251,  0.0514,  ..., -0.0682, -0.0392, -0.0653]],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([-0.0917,  0.0129,  0.0551,  0.0756,  0.0483, -0.0682, -0.0937, -0.0856,\n",
      "         0.0308,  0.0997, -0.0360, -0.0502, -0.0268,  0.0170,  0.0920,  0.0172,\n",
      "         0.0224, -0.0535,  0.0838, -0.0194, -0.0273, -0.0954,  0.0233, -0.0741,\n",
      "        -0.0765,  0.0019,  0.0375, -0.0998,  0.0346,  0.0691, -0.0162,  0.0442,\n",
      "         0.0222,  0.0361,  0.0156, -0.0923, -0.0576,  0.0794,  0.0505, -0.0670,\n",
      "        -0.0765,  0.0854, -0.0078, -0.0529,  0.0047,  0.0612,  0.0594, -0.0157,\n",
      "         0.0072, -0.0649, -0.0548, -0.0739,  0.0570, -0.0012,  0.0015, -0.0536,\n",
      "        -0.0103, -0.0064, -0.0023,  0.0721, -0.0891, -0.0243,  0.0036,  0.0331,\n",
      "        -0.0394, -0.0245,  0.0446,  0.0247, -0.0258, -0.0212,  0.0178,  0.0313,\n",
      "         0.0254,  0.0722,  0.0850,  0.0228, -0.0485, -0.0705,  0.0262, -0.0381,\n",
      "        -0.0529, -0.0736, -0.0549,  0.0379, -0.0612, -0.0609, -0.0773, -0.0187,\n",
      "        -0.0555, -0.0048, -0.0852,  0.0817,  0.0479, -0.0110, -0.0925,  0.0465,\n",
      "        -0.0389,  0.0591, -0.0519,  0.0755], requires_grad=True), Parameter containing:\n",
      "tensor([[-2.0349e-03,  4.3089e-02, -1.2810e-02, -4.8268e-02,  8.9748e-03,\n",
      "          3.1771e-02, -4.3859e-02,  1.6681e-02, -8.4843e-03, -1.2654e-02,\n",
      "         -7.4420e-03, -4.0014e-02,  2.7589e-02,  1.8265e-02,  6.6975e-02,\n",
      "         -2.5258e-02,  6.8796e-02, -1.6235e-02,  4.5528e-02,  7.6417e-02,\n",
      "         -8.9631e-02, -1.3401e-02,  9.6873e-02, -7.6174e-02, -2.2128e-02,\n",
      "          3.9492e-02, -7.2741e-02, -3.6317e-03,  9.9808e-02, -2.0196e-02,\n",
      "         -9.4807e-02, -1.4843e-02,  7.3168e-02, -6.4499e-02, -1.9526e-02,\n",
      "         -4.9223e-02, -8.7960e-02,  4.5995e-02,  1.0500e-02, -5.9577e-02,\n",
      "         -4.3923e-02, -7.1883e-02, -4.4215e-03, -7.9702e-02,  7.0948e-02,\n",
      "          3.6824e-02,  1.4108e-02, -1.5646e-02,  9.8971e-02, -4.0573e-02,\n",
      "          7.4174e-02, -3.1758e-02,  4.1780e-02,  6.4391e-02,  3.9274e-02,\n",
      "         -1.9806e-02, -5.3274e-02,  4.4499e-02,  6.2636e-02, -6.2009e-03,\n",
      "         -4.2662e-02,  3.2524e-02,  3.7909e-02, -7.8706e-02,  8.4800e-02,\n",
      "          1.3098e-02,  9.8496e-02, -8.0137e-02,  8.1149e-02,  5.3530e-02,\n",
      "         -3.7512e-02, -5.5164e-02,  8.1470e-02, -1.4117e-02, -2.4161e-02,\n",
      "         -3.9086e-02,  1.4330e-02,  3.0592e-02,  6.3424e-02, -7.4894e-02,\n",
      "          9.3767e-02,  2.7616e-02, -5.5744e-02, -5.3828e-02, -9.1231e-02,\n",
      "         -6.0642e-02,  6.6140e-02,  3.5806e-02, -1.5719e-02, -2.7705e-02,\n",
      "          1.5312e-02, -4.1161e-02,  1.2519e-02, -3.5671e-02, -2.2266e-02,\n",
      "         -8.2959e-02, -2.2676e-02, -6.1206e-03,  5.5024e-02, -6.0143e-02],\n",
      "        [ 1.2028e-02, -8.3478e-02,  7.3103e-02,  2.9240e-02, -1.8518e-02,\n",
      "          4.8880e-02,  5.6352e-02,  8.9807e-02, -8.6463e-03,  1.6613e-02,\n",
      "          9.7178e-02,  1.7543e-02,  5.9851e-02, -1.6078e-02, -5.6452e-02,\n",
      "         -5.2934e-03,  9.2219e-02,  4.4483e-02, -4.9139e-02, -1.0649e-02,\n",
      "         -7.3702e-02,  5.3122e-02, -4.9094e-02,  3.2101e-03,  6.9440e-02,\n",
      "          2.8053e-02, -7.8382e-02,  6.5254e-02,  6.1369e-05, -5.6437e-02,\n",
      "         -3.1849e-03,  4.3326e-02,  3.7316e-02,  9.8620e-02,  2.5237e-03,\n",
      "          1.7753e-02, -3.5046e-02, -3.9911e-02, -3.1545e-02,  5.7044e-02,\n",
      "          8.4002e-02,  6.5821e-02, -9.2502e-02, -4.3664e-02,  6.5321e-02,\n",
      "          2.0080e-03,  5.7849e-02,  8.8667e-02, -5.8142e-02,  4.2824e-02,\n",
      "          5.3391e-02,  4.1537e-02,  2.9905e-02, -9.0574e-02,  5.1266e-04,\n",
      "         -1.4793e-02, -8.0660e-02, -8.5808e-02,  9.8336e-03, -1.9503e-02,\n",
      "         -5.2614e-02, -1.7891e-02,  3.8928e-02,  9.3521e-02, -1.7136e-02,\n",
      "          5.2393e-02,  3.4707e-02, -9.9723e-02, -9.7057e-02,  2.8899e-02,\n",
      "          3.2799e-02,  1.1794e-03, -3.2540e-02,  9.6191e-02,  1.8463e-03,\n",
      "          7.5276e-02, -9.2901e-02,  4.6089e-03,  8.7989e-02,  4.7257e-02,\n",
      "          8.5812e-02, -1.3846e-02, -2.0245e-02,  6.7658e-02, -2.3251e-02,\n",
      "         -5.8927e-02, -7.4895e-02, -5.8130e-02, -4.9229e-02,  1.8401e-02,\n",
      "          8.2602e-02, -7.8527e-02,  2.5944e-02, -8.5570e-02, -8.2677e-02,\n",
      "          5.0749e-02, -3.8385e-02,  7.4729e-03,  7.6489e-02,  3.8614e-03],\n",
      "        [-3.9790e-02, -8.7150e-02, -5.6694e-02, -3.1346e-02, -6.2546e-02,\n",
      "         -7.7292e-02, -3.0007e-02, -6.5139e-02,  3.1865e-02,  1.7086e-02,\n",
      "          1.9916e-02, -7.9564e-02,  4.0163e-02, -9.9110e-02, -2.7867e-02,\n",
      "          4.7304e-02, -4.1061e-02, -9.9219e-02, -8.0192e-02,  6.3102e-02,\n",
      "          3.9398e-02,  6.3490e-03,  4.1474e-02, -3.9536e-02,  3.5552e-02,\n",
      "         -2.2419e-02, -4.9346e-02, -4.8724e-02, -5.0334e-02,  6.1496e-02,\n",
      "         -6.7964e-02,  3.1061e-02, -1.0018e-02, -5.9999e-02,  1.1138e-02,\n",
      "         -3.9194e-02, -3.6263e-02,  9.7377e-02,  8.5764e-02,  3.2298e-03,\n",
      "         -4.6636e-02, -3.3764e-02,  9.0920e-02, -7.9025e-02,  6.8010e-02,\n",
      "          6.0860e-02,  3.9285e-02,  4.3155e-02,  3.5652e-02,  5.7506e-02,\n",
      "         -3.3630e-02,  5.6376e-02,  8.2819e-03,  4.5135e-02, -3.2949e-02,\n",
      "         -9.0836e-02,  8.3328e-02,  1.3752e-02,  8.8410e-02, -5.0585e-02,\n",
      "         -9.7870e-02,  6.3827e-02,  1.1176e-02, -3.3897e-02,  4.8370e-02,\n",
      "         -6.9902e-02, -6.2507e-03, -6.8665e-02, -3.4125e-02,  7.6132e-02,\n",
      "         -5.1743e-02, -1.2754e-02, -1.2156e-02,  9.4160e-02,  4.5853e-02,\n",
      "          5.3114e-02, -4.2644e-02, -6.7935e-02, -4.0360e-03,  6.6218e-03,\n",
      "         -9.2083e-02, -7.8811e-02,  4.5968e-02, -3.1032e-02,  7.4493e-02,\n",
      "          3.3899e-02, -1.7594e-02, -4.4133e-02,  4.9459e-02,  4.0073e-02,\n",
      "         -6.8237e-02,  5.4164e-02, -5.4314e-02,  3.0390e-02,  8.5667e-02,\n",
      "          1.0269e-02,  1.5244e-02,  2.8916e-02, -1.4658e-02,  1.2784e-02],\n",
      "        [ 7.9686e-02, -3.8929e-02, -4.7607e-02, -9.9929e-02, -6.5611e-02,\n",
      "         -1.1406e-03,  5.5426e-02,  2.1864e-02, -3.9531e-02, -6.8971e-02,\n",
      "          4.9870e-02,  2.5193e-02,  7.9095e-02,  1.6837e-02, -3.1686e-02,\n",
      "          9.4267e-02, -1.9458e-02, -2.1414e-02, -6.2079e-03,  7.7460e-02,\n",
      "         -6.4869e-02, -2.0712e-02,  1.4489e-02, -4.1295e-02,  8.8383e-02,\n",
      "         -5.3621e-03, -7.9142e-02,  1.9015e-04, -9.0534e-02, -2.7406e-02,\n",
      "         -3.0195e-02, -4.0634e-02, -7.7839e-02, -4.7420e-03,  9.8608e-02,\n",
      "         -7.6541e-02, -9.3369e-02,  2.1505e-02, -5.8424e-02,  8.0410e-02,\n",
      "          5.4433e-02,  2.7624e-02,  5.6141e-02,  5.3261e-02, -1.2539e-02,\n",
      "         -2.2224e-02, -9.3805e-02, -2.1414e-02, -8.7244e-02,  6.5680e-02,\n",
      "         -7.3834e-02,  3.1126e-02,  8.3084e-02,  3.6938e-02,  5.8604e-02,\n",
      "          5.7566e-02, -2.1206e-02,  1.1610e-02,  7.9593e-02, -7.9806e-03,\n",
      "         -7.8124e-02,  7.7750e-02, -1.7267e-02, -1.3812e-02, -8.0942e-02,\n",
      "          1.2523e-02, -1.0706e-02,  4.5216e-02, -1.0648e-02,  9.0520e-02,\n",
      "         -3.8882e-02, -5.3166e-02, -8.8788e-02,  4.0312e-02, -4.7842e-03,\n",
      "         -8.1488e-02,  4.8436e-02, -1.5704e-02,  8.2526e-02,  5.8653e-02,\n",
      "         -7.4402e-02,  8.0037e-02, -6.8643e-02,  3.0038e-02,  6.7110e-02,\n",
      "         -1.7765e-02,  8.3656e-02,  4.5762e-02, -1.1164e-02,  1.8344e-02,\n",
      "          5.4596e-02,  2.4172e-02,  1.0335e-02,  6.8447e-02, -7.0550e-02,\n",
      "          3.5683e-02,  2.2059e-03, -4.5968e-02, -5.5488e-02,  4.2896e-02],\n",
      "        [ 5.2705e-02,  9.4192e-02,  6.6670e-02,  6.8891e-02, -1.1772e-02,\n",
      "          1.6991e-02,  6.5971e-02, -1.8725e-02,  9.0410e-02,  6.6169e-02,\n",
      "          3.5958e-02, -1.0083e-02,  3.0251e-03,  9.9017e-02, -2.0826e-02,\n",
      "          5.9290e-02, -3.6773e-02,  7.6019e-02,  2.0431e-02, -7.7344e-02,\n",
      "          3.0901e-02,  8.4894e-02, -2.4261e-02,  1.5921e-02,  9.3395e-02,\n",
      "          2.6519e-02, -1.5480e-02,  7.3182e-02, -2.6930e-02,  9.8355e-02,\n",
      "         -6.7787e-02, -5.8964e-02, -4.9981e-02, -9.1127e-03,  6.3426e-02,\n",
      "          1.5676e-02,  3.7489e-02, -9.3899e-02,  1.9705e-02,  9.6752e-03,\n",
      "          5.0755e-02, -7.4931e-02,  4.8424e-02, -1.2268e-02, -7.2841e-02,\n",
      "          6.7075e-02,  8.8266e-02, -2.6911e-02,  6.9802e-02,  9.4401e-02,\n",
      "         -1.0529e-02,  9.5151e-02,  1.4417e-02,  2.1570e-02, -7.6770e-03,\n",
      "         -3.3606e-02, -9.3294e-02,  5.8308e-03, -5.2027e-02, -2.3210e-02,\n",
      "          8.4415e-02, -4.0142e-02,  1.0824e-02,  1.1611e-02,  7.1986e-02,\n",
      "          1.1671e-02, -7.0301e-02,  6.6694e-02,  5.7521e-02, -6.9468e-02,\n",
      "         -9.4720e-02, -1.1767e-02, -1.4244e-02,  9.2664e-02, -7.5892e-02,\n",
      "          7.3039e-02,  5.1218e-02, -8.3817e-02,  3.1875e-02,  1.5660e-02,\n",
      "         -1.6671e-02, -7.1286e-02,  5.8535e-02, -8.9777e-02, -1.3277e-02,\n",
      "          2.1356e-02, -6.6525e-02, -6.4187e-02, -4.2488e-03,  6.9569e-02,\n",
      "          4.6296e-02, -9.8640e-02,  1.1963e-02,  3.4203e-02, -9.3682e-02,\n",
      "          2.3019e-02,  3.6404e-02,  3.7960e-02,  3.3554e-02,  1.5117e-02],\n",
      "        [-6.2724e-02, -3.8792e-03, -9.9881e-02, -5.0694e-02, -9.7876e-02,\n",
      "         -9.8732e-02,  4.2537e-02,  5.9911e-02, -4.2696e-02, -5.3001e-02,\n",
      "         -1.6760e-02, -5.3901e-02,  7.5160e-02, -6.7935e-02,  2.3850e-02,\n",
      "          8.8366e-02, -7.3319e-02,  4.2720e-03, -3.7793e-02, -7.5293e-02,\n",
      "          4.1286e-02,  2.2706e-02,  5.1677e-02, -6.1650e-02, -2.0902e-03,\n",
      "         -4.2503e-02,  7.5482e-02,  5.5544e-02,  2.0137e-02,  9.3777e-02,\n",
      "          3.6923e-02, -5.9786e-04, -1.0130e-03,  2.2807e-02, -7.3660e-02,\n",
      "          2.1785e-02, -4.1665e-02, -8.7852e-02, -7.7309e-02, -1.4147e-02,\n",
      "         -3.9259e-02, -2.5853e-02, -3.4859e-02,  3.6636e-02, -7.6500e-02,\n",
      "          2.2548e-02,  6.2714e-02, -3.8397e-02, -5.6628e-02,  8.1916e-02,\n",
      "          6.6721e-02,  3.2315e-02,  1.4825e-02,  2.0824e-02, -6.3803e-02,\n",
      "         -2.2149e-02,  8.1967e-02, -5.2816e-02,  7.3259e-02, -3.5011e-02,\n",
      "          1.9417e-02,  8.6789e-02,  2.5841e-02,  2.1612e-02,  5.6046e-02,\n",
      "          1.2472e-02,  2.7631e-02,  2.4235e-02, -6.2719e-02, -3.8228e-02,\n",
      "          6.7414e-02,  9.7075e-02, -9.5458e-02,  7.1588e-02,  7.8976e-02,\n",
      "          8.9513e-02,  3.3756e-02, -5.2539e-02, -6.3762e-02, -2.9350e-02,\n",
      "         -7.6288e-02, -1.3873e-02, -9.5288e-02,  4.5073e-02, -9.6280e-02,\n",
      "          6.5167e-02, -7.7574e-02,  2.2474e-02, -2.6798e-02, -3.9352e-02,\n",
      "          4.0355e-02,  6.0401e-02,  5.5806e-02, -1.5859e-02,  1.2816e-02,\n",
      "         -4.7302e-02,  7.2750e-03, -6.8148e-02, -7.3068e-02,  6.8045e-02],\n",
      "        [ 2.6456e-02, -4.2688e-02, -4.9420e-03,  8.5753e-02, -2.7217e-02,\n",
      "         -3.7192e-02,  4.3453e-02,  4.7143e-02,  1.1457e-02, -8.1208e-03,\n",
      "         -9.1208e-02,  6.4927e-02, -9.4809e-02, -2.4658e-02, -4.5381e-02,\n",
      "          2.3776e-02,  7.0366e-02, -4.5972e-02, -2.2551e-02,  6.4511e-02,\n",
      "         -6.8331e-02,  9.3712e-03,  6.9688e-02, -7.3677e-02, -2.8379e-02,\n",
      "         -1.6641e-02, -1.5731e-02,  2.2781e-02, -8.8841e-02,  5.7020e-02,\n",
      "         -3.8591e-02, -8.2876e-02, -7.0349e-02, -2.6132e-02,  2.7518e-02,\n",
      "         -2.4937e-02, -6.3009e-02, -3.3098e-02, -9.8206e-02, -6.8283e-02,\n",
      "          2.3694e-02, -4.9196e-02, -8.1736e-02,  8.2020e-02, -5.8060e-02,\n",
      "         -7.0870e-02, -1.2699e-02,  6.7650e-02, -5.4611e-02,  2.5718e-02,\n",
      "          9.7924e-02,  8.1236e-02, -2.2938e-02, -1.2522e-04,  3.0274e-02,\n",
      "         -2.7031e-02,  6.6963e-02,  9.1079e-02, -7.5516e-03,  8.2849e-02,\n",
      "         -9.4253e-02, -7.1823e-02, -6.6293e-02, -4.1640e-02, -8.2350e-02,\n",
      "          9.8311e-02,  3.1143e-02, -5.9728e-02, -2.5287e-02,  4.6477e-02,\n",
      "         -5.8989e-02, -4.8390e-02, -9.6892e-02, -2.2356e-02,  9.4983e-02,\n",
      "          6.1307e-02, -6.5583e-02, -2.4261e-02, -5.9669e-02, -4.2040e-02,\n",
      "          3.3183e-02,  9.7079e-02,  6.3075e-02, -1.7740e-02, -9.2407e-02,\n",
      "          4.4202e-02,  1.1888e-02,  1.6472e-02, -7.8719e-02, -8.6563e-03,\n",
      "          7.3282e-02,  5.9740e-02, -5.8047e-02, -2.0276e-03,  8.2854e-03,\n",
      "          5.6234e-02,  6.6092e-02, -4.3038e-02, -5.7017e-02,  1.8317e-02],\n",
      "        [-1.3432e-02, -7.0042e-02,  1.6245e-02,  3.8528e-02,  7.1717e-02,\n",
      "          5.8354e-02, -9.8360e-02,  9.0739e-02,  6.4788e-02,  2.1265e-02,\n",
      "         -6.4743e-02,  2.5691e-02,  8.1265e-02, -3.5489e-02, -6.5845e-02,\n",
      "         -3.5464e-02,  3.9532e-02,  9.1231e-03, -8.2601e-02,  1.4335e-02,\n",
      "          4.4381e-02,  2.9452e-02, -6.0477e-02, -5.9491e-02,  7.0916e-03,\n",
      "         -5.5409e-02,  4.6348e-02,  7.5483e-02,  8.6581e-02,  2.1502e-02,\n",
      "          9.5913e-02, -6.9073e-02, -7.2727e-02, -7.6277e-02, -4.1354e-02,\n",
      "          6.4391e-03,  1.5911e-02,  8.2531e-02, -8.1540e-02, -3.7437e-02,\n",
      "          2.9138e-02, -1.9245e-02, -1.7618e-02, -4.5283e-02, -9.5667e-02,\n",
      "          5.5892e-02,  9.1036e-02, -7.2059e-02, -9.2782e-02,  6.1422e-02,\n",
      "          7.1038e-02,  3.7811e-02, -4.4272e-02,  9.8023e-02,  5.2364e-02,\n",
      "         -3.6900e-02,  9.7594e-02, -2.5541e-02, -6.5632e-03,  5.8136e-03,\n",
      "         -9.8853e-02,  6.5304e-03, -3.1253e-02, -2.1625e-03,  5.8821e-02,\n",
      "         -3.7599e-02,  3.0990e-03, -7.5995e-02, -8.3599e-03,  2.6449e-02,\n",
      "         -2.5462e-02, -1.8179e-02, -8.5462e-02,  7.7741e-02, -6.8275e-02,\n",
      "          2.2426e-02,  1.6329e-02,  1.9088e-02,  9.8682e-02,  8.6491e-02,\n",
      "         -4.9549e-02,  6.4400e-02,  5.6636e-02, -5.0255e-02,  1.2259e-02,\n",
      "          1.2450e-03, -8.8604e-02, -1.8683e-02, -3.9304e-03,  3.5733e-03,\n",
      "         -6.4555e-02, -7.7414e-02,  1.8854e-02,  5.5904e-02, -1.8059e-02,\n",
      "         -7.3112e-02, -7.8819e-02,  8.1761e-03, -7.9334e-02,  6.3884e-02],\n",
      "        [-5.6773e-03,  8.4654e-02, -8.6812e-02,  3.6537e-02, -7.2912e-02,\n",
      "          7.2324e-02,  2.8218e-02,  8.7489e-02,  1.1125e-02,  1.7553e-02,\n",
      "         -2.4601e-02, -7.3808e-02,  7.6026e-02, -2.4317e-02, -7.6672e-02,\n",
      "         -1.3471e-02,  2.0486e-02, -9.6594e-02, -1.4802e-02,  6.9182e-02,\n",
      "         -2.3070e-02, -8.3424e-02, -2.0332e-02, -1.9315e-02,  7.3696e-02,\n",
      "         -5.7041e-02,  5.4000e-02, -2.3711e-02,  8.8268e-02, -1.1325e-02,\n",
      "         -9.5618e-02, -3.8172e-02, -6.9775e-02, -4.1037e-02, -7.5788e-02,\n",
      "         -9.2302e-02, -7.4283e-02, -5.4323e-02,  2.2291e-03, -2.1626e-03,\n",
      "          7.5540e-02, -6.3083e-02,  8.1506e-02,  3.0440e-02, -7.4989e-02,\n",
      "         -2.6776e-02, -3.1492e-02, -3.2737e-02, -4.1493e-02, -5.3098e-02,\n",
      "         -3.9176e-02, -2.6691e-02,  6.5046e-02,  4.0090e-02,  1.7114e-03,\n",
      "          3.8832e-02,  3.3724e-02,  6.2138e-02,  8.3355e-02,  4.7248e-02,\n",
      "          1.4153e-02,  8.0162e-02, -7.7817e-02,  1.2362e-02, -9.8054e-02,\n",
      "         -5.3331e-02, -2.2041e-02, -5.8405e-02,  4.2311e-03,  5.0067e-02,\n",
      "         -1.0097e-02,  9.4856e-02, -5.4775e-02,  1.5495e-02,  9.5326e-03,\n",
      "          3.1191e-03, -5.7843e-02, -2.4485e-02, -7.1106e-02, -2.9379e-02,\n",
      "          7.5152e-02,  4.3459e-02, -4.1316e-03, -3.0785e-02,  9.8662e-02,\n",
      "          4.0033e-02,  2.6842e-02,  2.5587e-02,  6.7264e-02, -1.9808e-02,\n",
      "          2.9980e-02, -6.7707e-02,  2.5235e-02,  6.6194e-02,  4.3946e-02,\n",
      "         -1.2519e-02,  8.2393e-02, -6.1989e-02,  6.3113e-02,  2.1584e-02],\n",
      "        [ 6.5812e-02, -4.5387e-02, -7.2167e-02, -2.3837e-02, -3.9469e-02,\n",
      "          9.8866e-02, -8.4156e-02, -2.8129e-03,  4.7594e-02,  1.9253e-02,\n",
      "         -2.7772e-02, -2.8413e-03, -2.8974e-02, -4.0954e-02,  1.0842e-02,\n",
      "          9.3018e-02,  1.0663e-02,  6.3759e-02,  2.1292e-02, -9.8376e-02,\n",
      "         -4.4843e-02,  2.4462e-02,  3.2575e-02,  7.2161e-02,  5.8715e-02,\n",
      "         -5.6101e-03,  2.8222e-02, -3.7826e-02, -3.8431e-02,  3.8091e-03,\n",
      "          1.5125e-03, -4.6314e-02,  4.6745e-02,  8.2829e-02,  7.7029e-02,\n",
      "          3.3955e-02, -4.9888e-02,  2.3629e-02, -4.0041e-02,  1.0185e-02,\n",
      "          6.2303e-03,  8.3999e-02,  2.8556e-03,  1.5038e-02, -7.9071e-02,\n",
      "         -4.3576e-02, -6.3477e-02,  2.7683e-02,  5.7239e-02, -9.5133e-02,\n",
      "          4.1740e-02, -1.2912e-02, -4.7970e-03, -1.2415e-02,  7.5801e-02,\n",
      "          4.5149e-02,  7.8794e-02, -9.2698e-02, -1.7214e-02,  8.6782e-02,\n",
      "          8.1955e-02,  7.6062e-02,  5.7403e-02,  8.2235e-02,  8.1066e-02,\n",
      "         -7.8322e-02, -5.3064e-02, -6.3029e-02,  6.7400e-02,  3.9834e-02,\n",
      "          6.7524e-02, -6.3320e-02, -7.6567e-03, -7.4366e-02, -1.3617e-02,\n",
      "          2.3857e-02, -4.6927e-02,  5.7010e-03,  4.4999e-03,  9.4754e-02,\n",
      "         -3.3434e-02,  7.2446e-02, -5.9415e-02, -3.1385e-02,  8.1587e-03,\n",
      "         -9.1215e-02,  1.8251e-03,  5.1853e-02, -4.5954e-02,  7.9261e-02,\n",
      "         -6.6498e-02,  6.6855e-02, -2.1928e-02,  2.1467e-02, -7.3828e-02,\n",
      "          4.4670e-02,  8.3063e-02,  7.5294e-02, -3.9426e-02, -9.1331e-02]],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([ 0.0564,  0.0462, -0.0106, -0.0216,  0.0688,  0.0499, -0.0752,  0.0516,\n",
      "        -0.0268, -0.0758], requires_grad=True), Parameter containing:\n",
      "tensor([[-0.3099, -0.0449, -0.0531, -0.1252, -0.0317, -0.2379, -0.0558,  0.0655,\n",
      "         -0.0511, -0.2417],\n",
      "        [ 0.1004, -0.1231, -0.0657, -0.0388, -0.2918,  0.2118, -0.0170,  0.1832,\n",
      "         -0.1761, -0.1406],\n",
      "        [ 0.0097, -0.0226,  0.2190, -0.3028, -0.2323,  0.0344,  0.1029, -0.2236,\n",
      "         -0.1002, -0.1313],\n",
      "        [-0.3113,  0.1098,  0.1270,  0.1172,  0.3096,  0.2970,  0.1565, -0.0455,\n",
      "         -0.0055,  0.2569],\n",
      "        [ 0.0447, -0.2131,  0.1094,  0.0288,  0.2801, -0.1968,  0.0892, -0.0391,\n",
      "          0.2906, -0.2488]], requires_grad=True), Parameter containing:\n",
      "tensor([ 0.3139, -0.1632,  0.2428, -0.1426,  0.1509], requires_grad=True)]\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(100,100).clone().detach()\n",
    "class Model(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear1 = torch.nn.Linear(100,100,bias=True)\n",
    "        self.linear2 = torch.nn.Linear(100,10,bias=True)\n",
    "        self.linear3 = torch.nn.Linear(10,5,bias=True)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        x = self.linear1(x)\n",
    "        x = self.linear2(x)\n",
    "        x = self.linear3(x)\n",
    "        return x\n",
    "    \n",
    "model = Model()\n",
    "print([name for name in model.parameters()])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0000, 0.5000, 0.5000, 0.5000],\n",
      "        [1.0000, 0.5000, 0.5000, 0.5000]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.softmax(torch.Tensor(2,4),dim=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text, tokenizer):\n",
    "    # berts tokenize ways\n",
    "    # tokenize the [unused12345678910]\n",
    "    D = [f\"[unused{i}]\" for i in range(10)]\n",
    "    textraw = [text]\n",
    "    for delimiter in D:\n",
    "        ntextraw = []\n",
    "        for i in range(len(textraw)):\n",
    "            t = textraw[i].split(delimiter)\n",
    "            for j in range(len(t)):\n",
    "                ntextraw += [t[j]]\n",
    "                if j != len(t)-1:\n",
    "                    ntextraw += [delimiter]\n",
    "        textraw = ntextraw\n",
    "    text = []\n",
    "    for t in textraw:\n",
    "        if t in D:\n",
    "            text += [t]\n",
    "        else:\n",
    "            tokens = tokenizer.tokenize(t, add_special_tokens=False)\n",
    "            for tok in tokens:\n",
    "                text += [tok]\n",
    "\n",
    "    for idx, t in enumerate(text):\n",
    "        if idx + 3 < len(text) and t == \"[\" and text[idx+1] == \"[UNK]\" and text[idx+2] == \"]\":\n",
    "            text = text[:idx] + [\"[MASK]\"] + text[idx+3:]\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f543a19e2b4f406b905ac8787121f4f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)/main/tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'just', 'say', ',', 'you', 'are', 'right', ',', 'and', 'i', 'believe', 'you', 'forever']\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "token = \"i just say ,you are right,and i believe you forever\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "print(tokenize(token,tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2]\n"
     ]
    }
   ],
   "source": [
    "d = {1:\"a\",2:\"b\"}\n",
    "print(list(d.keys()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "knowprompt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
